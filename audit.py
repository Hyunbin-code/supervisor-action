import os
import json
import logging
import requests
from openai import OpenAI
from github import Github
from tenacity import retry, stop_after_attempt, wait_exponential

# Setup Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Supervisor")

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
SUPERVISOR_HQ_URL = os.getenv("SUPERVISOR_HQ_URL")
HQ_SECRET = os.getenv("HQ_SECRET") # Shared secret for auth
dry_run = os.getenv("DRY_RUN", "false").lower() == "true"

MODEL = "gpt-4o-mini"
MAX_PATCH_LENGTH = 15000 # Limit context to save tokens

SYSTEM_PROMPT = """
You are Supervisor, a ruthlessly logical AI Auditor.
Analyze the provided Code Diff (Patch) for the following defects.
Focus ONLY on the changes (lines starting with +).

1. Hallucination: Importing non-existent packages, calling made-up functions.
2. Security: Leaking secrets, SQL injection, unsafe eval().
3. Logic: Broken flow, infinite loops, off-by-one errors.

Return JSON:
{
  "is_safe": boolean,
  "risk_score": integer (0-100),
  "issues": [
    {
        "file": "filename",
        "type": "HALLUCINATION" | "SECURITY" | "LOGIC",
        "severity": "HIGH" | "MEDIUM",
        "description": "Short explanation",
        "line": "approximate line number or code snippet"
    }
  ],
  "summary": "1 sentence executive summary"
}
"""

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
def analyze_with_llm(context: str) -> dict:
    client = OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"Analyze these changes:\n\n{context}"}
        ],
        response_format={"type": "json_object"}
    )
    return json.loads(response.choices[0].message.content)

def main():
    if not GITHUB_TOKEN or not OPENAI_API_KEY:
        logger.error("Missing Keys: GITHUB_TOKEN or OPENAI_API_KEY")
        return

    g = Github(GITHUB_TOKEN)
    repo_name = os.getenv("GITHUB_REPOSITORY")
    pr_number = os.getenv("PR_NUMBER")

    if not pr_number:
        logger.warning("No PR_NUMBER found. Exiting.")
        return

    logger.info(f"üîç Starting Audit for {repo_name} PR #{pr_number}")
    repo = g.get_repo(repo_name)
    pr = repo.get_pull(int(pr_number))

    # 1. Fetch & Filter Diffs
    diff_buffer = ""
    auditable_exts = {".py", ".js", ".ts", ".jsx", ".tsx", ".go", ".rs", ".java", ".c", ".cpp"}
    
    file_count = 0
    for file in pr.get_files():
        _, ext = os.path.splitext(file.filename)
        if ext not in auditable_exts:
            continue
        if file.status == "removed":
            continue
            
        patch = file.patch or "[No Diff Content]"
        # Append to buffer
        diff_buffer += f"--- File: {file.filename} ---\n{patch}\n\n"
        file_count += 1
        
        if len(diff_buffer) > MAX_PATCH_LENGTH:
            logger.warning("Diff buffer limit reached. Truncating further files.")
            diff_buffer += "\n[...Truncated due to token limits...]"
            break

    if file_count == 0:
        logger.info("No auditable files found in this PR.")
        return

    # 2. Analyze
    try:
        logger.info(f"sending {len(diff_buffer)} chars to {MODEL}...")
        result = analyze_with_llm(diff_buffer)
    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        return

    risk_score = result.get("risk_score", 0)
    logger.info(f"‚úÖ Audit Complete. Risk Score: {risk_score}")

    # 3. Comment on GitHub (Only if issues found or High Risk)
    if risk_score > 0 and len(result.get("issues", [])) > 0:
        if not dry_run:
            body = f"## üõ°Ô∏è Supervisor Audit Report (Risk: {risk_score}/100)\n\n"
            body += f"**Summary**: {result.get('summary')}\n\n"
            for issue in result.get("issues", []):
                icon = "üö®" if issue['severity'] == "HIGH" else "‚ö†Ô∏è"
                body += f"### {icon} {issue['file']}: {issue['type']}\n"
                body += f"- **Propblem**: {issue['description']}\n"
                body += f"- **Location**: `{issue['line']}`\n"
            
            body += "\n---\n*Generated by Supervisor.ai*"
            pr.create_issue_comment(body)
            logger.info("Comment posted to PR.")
        else:
            logger.info("Dry Run: Skipping PR comment.")

    # 4. Report to HQ (Parasitic Payload)
    if SUPERVISOR_HQ_URL and HQ_SECRET:
        try:
            payload = {
                "repo": repo_name,
                "pr_number": pr_number,
                "commit_sha": pr.head.sha,
                "actor": pr.user.login,
                "is_safe": risk_score < 50,
                "risk_score": risk_score,
                "issues": result.get("issues"),
                "full_report": result
            }
            headers = {"x-supervisor-secret": HQ_SECRET}
            res = requests.post(SUPERVISOR_HQ_URL, json=payload, headers=headers, timeout=5)
            logger.info(f"Report sent to HQ: {res.status_code}")
        except Exception as e:
            logger.warning(f"HQ Reporting failed: {e}")

if __name__ == "__main__":
    main()
